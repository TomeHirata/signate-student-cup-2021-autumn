{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing「前処理」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ読み込み\n",
    "station = pd.read_csv('station.csv')\n",
    "trip = pd.read_csv('trip.csv')\n",
    "status = pd.read_csv('status.csv')\n",
    "weather = pd.read_csv('weather.csv')\n",
    "sample_submission = pd.read_csv('sample_submit.csv', header=None, names=['id','count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date系カラムの整理\n",
    "trip.start_date=trip.start_date.apply(lambda n: datetime.datetime.strptime(n, '%m/%d/%Y %H:%M' ))\n",
    "weather.date=weather.date.apply(lambda n: datetime.datetime.strptime(n, '%Y-%m-%d' ))\n",
    "weather[\"month\"] = weather.date.apply(lambda n: n.month)\n",
    "weather[\"year\"] = weather.date.apply(lambda n: n.year)\n",
    "weather[\"day\"] = weather.date.apply(lambda n: n.day)\n",
    "weather[\"weekday\"] = weather.date.apply(lambda n: n.weekday())\n",
    "station.installation_date = station.installation_date.apply(lambda n: datetime.datetime.strptime(n, '%m/%d/%Y' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "# 乱数シードの固定\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seed(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習・予測用のデータを整形\n",
    "status = status.merge(station, on=\"station_id\").merge(weather, on=[\"year\",\"month\",\"day\"])\n",
    "train_status = status[status.predict==0].merge(station, on=\"station_id\")\n",
    "train_status = train_status[train_status.bikes_available.isnull() == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning「学習」\n",
    "今回は時系列モデルや回帰モデルを使用していないものを最終スコアの提出に用いたので学習フェーズは割愛します\n",
    "CVだけ計算します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameters\n",
    "date_span = 180\n",
    "min_date_count = 20\n",
    "alpha = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dates = np.unique(train_status.date.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 過去のデータがない日はバリデーションの予測日にできない\n",
    "val_dates = train_dates[train_dates>station.installation_date.max() + datetime.timedelta(days=30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 10000\n",
      "iter: 20000\n",
      "iter: 30000\n",
      "iter: 40000\n",
      "iter: 50000\n",
      "iter: 60000\n",
      "iter: 70000\n",
      "iter: 80000\n",
      "iter: 90000\n",
      "iter: 100000\n",
      "iter: 110000\n",
      "iter: 120000\n",
      "iter: 130000\n",
      "RMSE: 3.343846553329613\n",
      "iter: 10000\n",
      "iter: 20000\n",
      "iter: 30000\n",
      "iter: 40000\n",
      "iter: 50000\n",
      "iter: 60000\n",
      "iter: 70000\n",
      "iter: 80000\n",
      "iter: 90000\n",
      "iter: 100000\n",
      "iter: 110000\n",
      "iter: 120000\n",
      "iter: 130000\n",
      "RMSE: 3.4162244217775957\n",
      "iter: 10000\n",
      "iter: 20000\n",
      "iter: 30000\n",
      "iter: 40000\n",
      "iter: 50000\n",
      "iter: 60000\n",
      "iter: 70000\n",
      "iter: 80000\n",
      "iter: 90000\n",
      "iter: 100000\n",
      "iter: 110000\n",
      "iter: 120000\n",
      "iter: 130000\n",
      "RMSE: 3.2708297865590956\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=3, shuffle=True)\n",
    "scores = []\n",
    "for _, val_index in kf.split(val_dates):\n",
    "    t_status, v_status = train_status[~train_status.date.isin(val_dates[val_index])], train_status[train_status.date.isin(val_dates[val_index])]\n",
    "    pred = []\n",
    "    i = 1\n",
    "    for row in v_status.itertuples():\n",
    "        if i % 10000 == 0:\n",
    "            print(f\"iter: {i}\")\n",
    "        i += 1\n",
    "        tmt_df = t_status[(t_status.date < row.date) & (t_status.date > row.date - datetime.timedelta(days=date_span)) & (t_status.hour == row.hour) & (t_status.station_id == row.station_id)]\n",
    "        a = t_status[(t_status.date < row.date) & (t_status.date >= row.date - datetime.timedelta(days=date_span//2)) & (t_status.hour == row.hour) & (t_status.station_id == row.station_id)]\n",
    "        b = t_status[(t_status.date < row.date - datetime.timedelta(days=date_span//2)) & (t_status.date >= row.date - datetime.timedelta(days=date_span)) & (t_status.hour == row.hour) & (t_status.station_id == row.station_id)]\n",
    "        if len(a) > min_date_count and len(b) > min_date_count:\n",
    "            diff = a.bikes_available.mean() - b.bikes_available.mean()\n",
    "        else:\n",
    "            diff=0\n",
    "        pred.append(tmt_df.bikes_available.mean() + diff/alpha)\n",
    "    score = ((v_status.bikes_available.values - np.array(pred))**2).mean() **0.5\n",
    "    print(f\"RMSE: {score}\")\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting「予測」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = sample_submission.merge(status, on='id').sort_values('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1000\n",
      "iter: 2000\n",
      "iter: 3000\n",
      "iter: 4000\n",
      "iter: 5000\n",
      "iter: 6000\n",
      "iter: 7000\n",
      "iter: 8000\n",
      "iter: 9000\n",
      "iter: 10000\n",
      "iter: 11000\n",
      "iter: 12000\n",
      "iter: 13000\n",
      "iter: 14000\n",
      "iter: 15000\n",
      "iter: 16000\n",
      "iter: 17000\n",
      "iter: 18000\n",
      "iter: 19000\n",
      "iter: 20000\n",
      "iter: 21000\n",
      "iter: 22000\n",
      "iter: 23000\n",
      "iter: 24000\n",
      "iter: 25000\n",
      "iter: 26000\n",
      "iter: 27000\n",
      "iter: 28000\n",
      "iter: 29000\n",
      "iter: 30000\n",
      "iter: 31000\n",
      "iter: 32000\n",
      "iter: 33000\n",
      "iter: 34000\n",
      "iter: 35000\n",
      "iter: 36000\n",
      "iter: 37000\n",
      "iter: 38000\n",
      "iter: 39000\n",
      "iter: 40000\n",
      "iter: 41000\n",
      "iter: 42000\n",
      "iter: 43000\n",
      "iter: 44000\n",
      "iter: 45000\n",
      "iter: 46000\n",
      "iter: 47000\n",
      "iter: 48000\n",
      "iter: 49000\n",
      "iter: 50000\n",
      "iter: 51000\n",
      "iter: 52000\n",
      "iter: 53000\n",
      "iter: 54000\n",
      "iter: 55000\n",
      "iter: 56000\n",
      "iter: 57000\n",
      "iter: 58000\n",
      "iter: 59000\n",
      "iter: 60000\n",
      "iter: 61000\n",
      "iter: 62000\n",
      "iter: 63000\n",
      "iter: 64000\n",
      "iter: 65000\n",
      "iter: 66000\n",
      "iter: 67000\n",
      "iter: 68000\n",
      "iter: 69000\n",
      "iter: 70000\n",
      "iter: 71000\n",
      "iter: 72000\n",
      "iter: 73000\n",
      "iter: 74000\n",
      "iter: 75000\n",
      "iter: 76000\n",
      "iter: 77000\n",
      "iter: 78000\n",
      "iter: 79000\n",
      "iter: 80000\n",
      "iter: 81000\n",
      "iter: 82000\n",
      "iter: 83000\n",
      "iter: 84000\n",
      "iter: 85000\n",
      "iter: 86000\n",
      "iter: 87000\n",
      "iter: 88000\n",
      "iter: 89000\n",
      "iter: 90000\n",
      "iter: 91000\n",
      "iter: 92000\n",
      "iter: 93000\n",
      "iter: 94000\n",
      "iter: 95000\n",
      "iter: 96000\n",
      "iter: 97000\n",
      "iter: 98000\n",
      "iter: 99000\n",
      "iter: 100000\n",
      "iter: 101000\n",
      "iter: 102000\n",
      "iter: 103000\n",
      "iter: 104000\n",
      "iter: 105000\n",
      "iter: 106000\n",
      "iter: 107000\n",
      "iter: 108000\n",
      "iter: 109000\n",
      "iter: 110000\n",
      "iter: 111000\n",
      "iter: 112000\n",
      "iter: 113000\n",
      "iter: 114000\n",
      "iter: 115000\n",
      "iter: 116000\n",
      "iter: 117000\n",
      "iter: 118000\n",
      "iter: 119000\n",
      "iter: 120000\n",
      "iter: 121000\n",
      "iter: 122000\n",
      "iter: 123000\n",
      "iter: 124000\n",
      "iter: 125000\n",
      "iter: 126000\n",
      "iter: 127000\n",
      "iter: 128000\n",
      "iter: 129000\n",
      "iter: 130000\n",
      "iter: 131000\n",
      "iter: 132000\n",
      "iter: 133000\n",
      "iter: 134000\n",
      "iter: 135000\n",
      "iter: 136000\n",
      "iter: 137000\n",
      "iter: 138000\n",
      "iter: 139000\n",
      "iter: 140000\n",
      "iter: 141000\n",
      "iter: 142000\n",
      "iter: 143000\n",
      "iter: 144000\n",
      "iter: 145000\n",
      "iter: 146000\n",
      "iter: 147000\n",
      "iter: 148000\n",
      "iter: 149000\n",
      "iter: 150000\n",
      "iter: 151000\n",
      "iter: 152000\n",
      "iter: 153000\n",
      "iter: 154000\n",
      "iter: 155000\n",
      "iter: 156000\n",
      "iter: 157000\n",
      "iter: 158000\n",
      "iter: 159000\n",
      "iter: 160000\n",
      "iter: 161000\n",
      "iter: 162000\n",
      "iter: 163000\n",
      "iter: 164000\n",
      "iter: 165000\n",
      "iter: 166000\n",
      "iter: 167000\n",
      "iter: 168000\n",
      "iter: 169000\n",
      "iter: 170000\n",
      "iter: 171000\n",
      "iter: 172000\n",
      "iter: 173000\n",
      "iter: 174000\n",
      "iter: 175000\n",
      "iter: 176000\n",
      "iter: 177000\n",
      "iter: 178000\n",
      "iter: 179000\n",
      "iter: 180000\n",
      "iter: 181000\n",
      "iter: 182000\n",
      "iter: 183000\n",
      "iter: 184000\n",
      "iter: 185000\n",
      "iter: 186000\n",
      "iter: 187000\n",
      "iter: 188000\n",
      "iter: 189000\n",
      "iter: 190000\n",
      "iter: 191000\n",
      "iter: 192000\n",
      "iter: 193000\n"
     ]
    }
   ],
   "source": [
    "result_d = {\n",
    "    \"id\": [],\n",
    "    \"bikes\": [],\n",
    "}\n",
    "i = 1\n",
    "for row in submit_df.itertuples():\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"iter: {i}\")\n",
    "    i += 1\n",
    "    tmt_df = train_status[(train_status.date < row.date) & (train_status.date > row.date - datetime.timedelta(days=date_span)) & (train_status.hour == row.hour) & (train_status.station_id == row.station_id)]\n",
    "    a = train_status[(train_status.date < row.date) & (train_status.date >= row.date - datetime.timedelta(days=date_span//2)) & (train_status.hour == row.hour) & (train_status.station_id == row.station_id)]\n",
    "    b = train_status[(train_status.date < row.date - datetime.timedelta(days=date_span//2)) & (train_status.date >= row.date - datetime.timedelta(days=date_span)) & (train_status.hour == row.hour) & (train_status.station_id == row.station_id)]\n",
    "    if len(a) > min_date_count and len(b) > min_date_count:\n",
    "        diff = a.bikes_available.mean() - b.bikes_available.mean()\n",
    "    else:\n",
    "        diff=0\n",
    "    result_d[\"bikes\"].append(tmt_df.bikes_available.mean() + diff/alpha)\n",
    "    result_d[\"id\"].append(row.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result_d).to_csv('final_submission.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
